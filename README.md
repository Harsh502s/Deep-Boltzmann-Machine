<h1>Deep Boltzmann Machine for Movie Recommendations</h1><p><em>A foundational from-scratch implementation of a Deep Boltzmann Machine (DBM) using PyTorch for collaborative filtering on the MovieLens 100k dataset.</em></p><h2>Introduction</h2><p>This project provides a clear and commented implementation of a Deep Boltzmann Machine (DBM), a type of deep generative neural network. It is specifically designed to function as a movie recommendation system by learning to predict user ratings. By training on the classic MovieLens 100k dataset, the model identifies complex patterns in user-movie interactions to distinguish between movies a user might like or dislike. This repository is ideal for students, researchers, and developers looking to understand the inner workings of DBMs and their application in real-world collaborative filtering scenarios.</p><h2>Key Features</h2><ul><li><strong>From-Scratch Implementation:</strong> The DBM is built from the ground up using fundamental PyTorch tensor operations, providing deep insight into its architecture without relying on high-level abstractions.</li><li><strong>Multi-Layer Architecture:</strong> Implements a DBM with multiple hidden layers (in this case, three) to capture hierarchical and complex feature representations from the data.</li><li><strong>Contrastive Divergence:</strong> Utilizes the Contrastive Divergence (CD-k) algorithm for efficient, unsupervised training of the generative model.</li><li><strong>Data Preprocessing:</strong> Includes a complete data handling pipeline to load, convert, and binarize the MovieLens 100k dataset for model consumption.</li><li><strong>Educational Focus:</strong> The code is extensively commented to explain each step, from data preparation to model training and evaluation, making it a great learning resource.</li></ul><h2>How It Works</h2><p>A Deep Boltzmann Machine is an undirected probabilistic graphical model with multiple layers of hidden variables. Unlike a Restricted Boltzmann Machine (RBM), a DBM allows connections between hidden layers, enabling it to learn more abstract and powerful feature representations.</p><p>The training process involves two main phases in a loop:</p><ol><li><strong>Positive Phase (Data-driven):</strong> The model is presented with real data (user ratings), and the activations of the hidden units are calculated. This represents the model's "perception" of the real world.</li><li><strong>Negative Phase (Model-driven):</strong> The model generates its own "fantasy" data through a process called Gibbs sampling. It alternates between sampling hidden states given visible states and vice-versa.</li></ol><p>The model's weights are then updated using <strong>Contrastive Divergence</strong> to minimize the difference between the positive (real) and negative (fantasy) phases. This process effectively teaches the model's internal representation to better match the structure of the real data, allowing it to make accurate predictions for unseen ratings.</p><h2>Getting Started</h2><h3>Prerequisites</h3><p>Ensure you have the following installed on your system:</p><ul><li>Python 3.8+</li><li>pip (Python package installer)</li></ul><h3>Installation Steps</h3><ol><li><strong>Clone the repository:</strong><pre><code>git clone https://github.com/Harsh502s/Deep-Boltzmann-Machine.git<br/>cd Deep-Boltzmann-Machine</code></pre></li><li><strong>Install dependencies:</strong> It is recommended to create and activate a virtual environment before installing the packages.<pre><code>pip install torch numpy pandas</code></pre></li><li><strong>Download the Dataset:</strong> This model requires the MovieLens 100k dataset. <ol><li>Download the dataset from the official <a href="https://grouplens.org/datasets/movielens/100k/" target="_blank" rel="noopener noreferrer">GroupLens website</a>.</li><li>Unzip the downloaded file to get a folder named <code>ml-100k</code>.</li><li>Place this folder in a location of your choice on your machine.</li></ol></li><li><strong>Update Dataset Paths:</strong> This is a critical step. Open the <code>Deep_boltzmann_machine.py</code> file and modify the hardcoded file paths for <code>training_set</code> and <code>test_set</code> to point to the <code>u1.base</code> and <code>u1.test</code> files inside your downloaded <code>ml-100k</code> folder.<pre><code># --- BEFORE (in the script) ---<br/>training_set = pd.read_csv(r"E:\Code\DL\ml-100k\u1.base", delimiter="\t")<br/>test_set = pd.read_csv(r"E:\Code\DL\ml-100k/u1.test", delimiter="\t")<br/><br/># --- AFTER (your changes - example) ---<br/>training_set = pd.read_csv("./ml-100k/u1.base", delimiter="\t")<br/>test_set = pd.read_csv("./ml-100k/u1.test", delimiter="\t")</code></pre></li></ol><h2>Usage</h2><p>Once the setup is complete, you can run the training and evaluation script from your terminal:</p><pre><code>python Deep_boltzmann_machine.py</code></pre><p>The script will initialize the DBM, process the data, and begin the training loop. It will print the training loss after each epoch and conclude by printing the final test loss, which indicates the model's performance on unseen data.</p><h3>Expected Output</h3><p>Your terminal output will look similar to this:</p><pre><code>Epoch: 0 Loss: tensor(0.2514)<br/>Epoch: 1 Loss: tensor(0.2478)<br/>...<br/>Epoch: 9 Loss: tensor(0.2455)<br/>Test Loss: tensor(0.2467)</code></pre><h2>Configuration</h2><p>You can easily experiment with the DBM's architecture and training hyperparameters by modifying the variables defined in the <code>Deep_boltzmann_machine.py</code> script:</p><pre><code># --- DBM Architecture ---<br/>nh1 = 10  # Number of units in the first hidden layer<br/>nh2 = 10  # Number of units in the second hidden layer<br/>nh3 = 10  # Number of units in the third hidden layer<br/><br/># --- Training Parameters ---<br/>batch_size = 100  # Number of samples per batch<br/>nb_epoch = 10     # Total number of training epochs</code></pre><h2>Technologies Used</h2><ul><li><strong>Python:</strong> The core programming language for the project.</li><li><strong>PyTorch:</strong> Used for all tensor operations, building the DBM components, and automatic differentiation.</li><li><strong>NumPy:</strong> For efficient numerical operations and initial data array manipulations.</li><li><strong>Pandas:</strong> For loading the dataset from delimited text files into a structured format.</li></ul><h2>Project Structure</h2><p>The project consists of a single primary script, keeping the structure simple and focused.</p><pre><code>Deep-Boltzmann-Machine/<br/>├── Deep_boltzmann_machine.py   # Main script containing the DBM class, data processing, training, and testing logic.<br/>└── README.md                   # This documentation file.</code></pre><h2>Contributing</h2><p>Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are <strong>greatly appreciated</strong>. Please follow these steps:</p><ol><li>Fork the Project</li><li>Create your Feature Branch (<code>git checkout -b feature/AmazingFeature</code>)</li><li>Commit your Changes (<code>git commit -m 'Add some AmazingFeature'</code>)</li><li>Push to the Branch (<code>git push origin feature/AmazingFeature</code>)</li><li>Open a Pull Request</li></ol><h2>License</h2><p>Distributed under the MIT License. See the <code>LICENSE</code> file in the repository for more information.</p><h2>Acknowledgments</h2><ul><li>This project uses the <a href="https://grouplens.org/datasets/movielens/100k/" target="_blank" rel="noopener noreferrer">MovieLens 100k Dataset</a>, kindly provided by the GroupLens Research Project at the University of Minnesota.</li><li>The implementation serves as an educational tool to demonstrate the fundamentals of Deep Boltzmann Machines.</li></ul>
